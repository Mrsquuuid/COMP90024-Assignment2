{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Modify previously harvested data\n",
    "\n",
    "## 1.1 Read Each Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import couchdb, afinn\n",
    "\n",
    "url_connect = \"http://admin:A456852s@127.0.0.1:5984\"\n",
    "couch = couchdb.Server(url_connect) \n",
    "\n",
    "db_name = \"a_twitter_test\"\n",
    "db = couch[db_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtain each document's ID:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "108"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_docs = [i for i in db.view('_all_docs', include_docs=True)]\n",
    "len(all_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample ID:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1382473379408539649'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_id = all_docs[0].id\n",
    "my_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample Doc:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_id': '1382473379408539649',\n",
       " '_rev': '2-c87cb8e7459525cd272f2302b8d9645d',\n",
       " 'created_at': 'Wed Apr 14 23:18:33 +0000 2021',\n",
       " 'id': 1382473379408539649,\n",
       " 'id_str': '1382473379408539649',\n",
       " 'text': 'Absolutely horrible first inning #Phillies',\n",
       " 'truncated': False,\n",
       " 'entities': {'hashtags': [{'text': 'Phillies', 'indices': [33, 42]}],\n",
       "  'symbols': [],\n",
       "  'user_mentions': [],\n",
       "  'urls': []},\n",
       " 'metadata': {'iso_language_code': 'en', 'result_type': 'recent'},\n",
       " 'source': '<a href=\"http://tapbots.com/tweetbot\" rel=\"nofollow\">Tweetbot for iΟS</a>',\n",
       " 'in_reply_to_status_id': None,\n",
       " 'in_reply_to_status_id_str': None,\n",
       " 'in_reply_to_user_id': None,\n",
       " 'in_reply_to_user_id_str': None,\n",
       " 'in_reply_to_screen_name': None,\n",
       " 'user': {'id': 76908648,\n",
       "  'id_str': '76908648',\n",
       "  'name': 'Chris Meister 🏏⚾️🏈🏒',\n",
       "  'screen_name': 'sportmeister_',\n",
       "  'location': 'Melbourne, Australia',\n",
       "  'description': 'Husband, father, lover of all sports @BentleighCC',\n",
       "  'url': 'https://t.co/chTa81tivY',\n",
       "  'entities': {'url': {'urls': [{'url': 'https://t.co/chTa81tivY',\n",
       "      'expanded_url': 'http://sportmeister.com.au',\n",
       "      'display_url': 'sportmeister.com.au',\n",
       "      'indices': [0, 23]}]},\n",
       "   'description': {'urls': []}},\n",
       "  'protected': False,\n",
       "  'followers_count': 712,\n",
       "  'friends_count': 614,\n",
       "  'listed_count': 40,\n",
       "  'created_at': 'Thu Sep 24 10:36:05 +0000 2009',\n",
       "  'favourites_count': 633,\n",
       "  'utc_offset': None,\n",
       "  'time_zone': None,\n",
       "  'geo_enabled': True,\n",
       "  'verified': False,\n",
       "  'statuses_count': 32398,\n",
       "  'lang': None,\n",
       "  'contributors_enabled': False,\n",
       "  'is_translator': False,\n",
       "  'is_translation_enabled': False,\n",
       "  'profile_background_color': '382D8A',\n",
       "  'profile_background_image_url': 'http://abs.twimg.com/images/themes/theme10/bg.gif',\n",
       "  'profile_background_image_url_https': 'https://abs.twimg.com/images/themes/theme10/bg.gif',\n",
       "  'profile_background_tile': True,\n",
       "  'profile_image_url': 'http://pbs.twimg.com/profile_images/1382460620918845441/d_heFN01_normal.jpg',\n",
       "  'profile_image_url_https': 'https://pbs.twimg.com/profile_images/1382460620918845441/d_heFN01_normal.jpg',\n",
       "  'profile_banner_url': 'https://pbs.twimg.com/profile_banners/76908648/1432245279',\n",
       "  'profile_link_color': 'ABB8C2',\n",
       "  'profile_sidebar_border_color': 'FFFFFF',\n",
       "  'profile_sidebar_fill_color': '7AC3EE',\n",
       "  'profile_text_color': '3D1957',\n",
       "  'profile_use_background_image': False,\n",
       "  'has_extended_profile': False,\n",
       "  'default_profile': False,\n",
       "  'default_profile_image': False,\n",
       "  'following': False,\n",
       "  'follow_request_sent': False,\n",
       "  'notifications': False,\n",
       "  'translator_type': 'none'},\n",
       " 'geo': None,\n",
       " 'coordinates': None,\n",
       " 'place': {'id': '2d770e49885342a2',\n",
       "  'url': 'https://api.twitter.com/1.1/geo/id/2d770e49885342a2.json',\n",
       "  'place_type': 'neighborhood',\n",
       "  'name': 'Bentleigh',\n",
       "  'full_name': 'Bentleigh, Melbourne',\n",
       "  'country_code': 'AU',\n",
       "  'country': 'Australia',\n",
       "  'contained_within': [],\n",
       "  'bounding_box': {'type': 'Polygon',\n",
       "   'coordinates': [[[145.02245796, -37.93472802],\n",
       "     [145.05236388, -37.93472802],\n",
       "     [145.05236388, -37.91080998],\n",
       "     [145.02245796, -37.91080998]]]},\n",
       "  'attributes': {}},\n",
       " 'contributors': None,\n",
       " 'is_quote_status': False,\n",
       " 'retweet_count': 0,\n",
       " 'favorite_count': 1,\n",
       " 'favorited': False,\n",
       " 'retweeted': False,\n",
       " 'lang': 'en',\n",
       " 'afinn': -3.0,\n",
       " 'vulgar_words': 0,\n",
       " 'crime_words': 0,\n",
       " 'covid_words': 0,\n",
       " 'vaccine_words': 0,\n",
       " 'vic_words': 0,\n",
       " 'alcohol_words': 0,\n",
       " 'china_words': 0,\n",
       " 'SA2_names': None,\n",
       " 'SA2_codes_9_digits': None,\n",
       " 'SA2_codes_5_digits': None}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_doc = dict(all_docs[0].doc)\n",
    "my_doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Calculate Sentiment Score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-3.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from afinn import Afinn\n",
    "afinn = Afinn()\n",
    "if \"full_text\" in my_doc:\n",
    "    text = my_doc[\"full_text\"]\n",
    "else:\n",
    "    text = my_doc[\"text\"]\n",
    "afinn.score(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Keyword Search\n",
    "\n",
    "### 1.3.1 Covid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def mention_time(text, keyword_list, delimiter):\n",
    "    return sum([1 if token.lower() in keyword_list else 0 for token in re.split(delimiter, text)])\n",
    "\n",
    "keywords_list = dict()\n",
    "\n",
    "delimiter = r\"[^a-zA-Z0-9\\-]\"\n",
    "\n",
    "# 15 Keywords\n",
    "keywords_list[\"covid_words\"] = [\"covid\", \"covid-19\", \"coronavirus\", \"antibodies\", \"vaccine\",\n",
    "                                \"antibody\", \"quarantine\", \"self-isolation\", \"epidemic\", \"immunity\", \n",
    "                                \"distancing\", \"sars-cov-2\", \"ventilator\", \"immunization\", \"tested\"]\n",
    "\n",
    "mention = mention_time(\"#coVid and #coviD-19 and ?sars-cOv-2!\", keywords_list[\"covid_words\"] , delimiter)\n",
    "mention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.2 COVID Vaccine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5 Keywords\n",
    "keywords_list[\"vaccine_words\"] = [\"vaccine\", \"pfizer\", \"biontech\", \"oxford\", \"astrazeneca\"]\n",
    "\n",
    "mention = mention_time(\">vaccine and [pfizer] and {oxford}\", keywords_list[\"vaccine_words\"], delimiter)\n",
    "mention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.3 Vulgar Words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 25 Keywords\n",
    "keywords_list[\"vulgar_words\"] = [\"asshole\", \"fyfi\", \"wfh\", \"shit\", \"damn\", \"fuck\", \"jerkoff\", \n",
    "                                  \"ass\", \"prick\", \"damn\", \"gtfo\", \"stfu\", \"goddamn\", \"fxxk\",\n",
    "                                  \"bitch\", \"wtf\", \"cunt\", \"cock\", \"dick\", \"frick\", \"pussy\", \n",
    "                                  \"cum\", \"fk\", \"fucker\", \"omfg\"]\n",
    "\n",
    "mention = mention_time(\"~~~fUck and #$%shit^% and damn!!\", keywords_list[\"vulgar_words\"], delimiter)\n",
    "mention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.4 China Related"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 10 Keywords\n",
    "keywords_list[\"china_words\"] = [\"china\", \"chinese\", \"ccp\", \"mandarin\", \"yuan\", \"chinatown\", \n",
    "                                \"beijing\", \"xinjiang\", \"australia–china\", \"sino-australia\"]\n",
    "\n",
    "mention = mention_time(\"China and YuAN¥ and XInJiang\", keywords_list[\"china_words\"], delimiter)\n",
    "mention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.5 Alcohol Related"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 25 Keywords\n",
    "keywords_list[\"alcohol_words\"] = [\"alcoholic\", \"drunk\", \"spirit\", \"alcohol\", \"cocktail\", \n",
    "                                  \"beer\", \"vodka\", \"corona\", \"bottle\", \"wine\", \"martini\", \"vb\",\n",
    "                                  \"asahi\", \"carlsberg\", \"whiskey\", \"pub\", \"casino\", \"hooch\", \n",
    "                                  \"booze\", \"shooter\", \"shot\", \"soju\", \"baijiu\", \"brandy\", \"bundaberg\"]\n",
    "\n",
    "mention = mention_time(\"sOJu and @VodKA&&&PUB!!!\", keywords_list[\"alcohol_words\"], delimiter)\n",
    "mention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.6 Crime Related"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 25 Keywords\n",
    "keywords_list[\"crime_words\"] = [\"crime\", \"criminal\", \"gun\", \"shoot\", \"robbery\", \"kidnap\", \"kidnapping\"\n",
    "                                \"kill\", \"murder\", \"assault\", \"drug\", \"fraud\", \"hacking\", \"homicide\",\n",
    "                                \"smuggling\", \"terrorism\", \"speeding\", \"theft\", \"prison\", \"sentence\", \n",
    "                                \"police\", \"felony\", \"killed\", \"drugs\", \"discrimination\", \"death\"]\n",
    "\n",
    "mention = mention_time(\"sOJu and @VodKA&&&PUB!!!\", keywords_list[\"crime_words\"], delimiter)\n",
    "mention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.7 VIC Government"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5 Keywords\n",
    "keywords_list[\"vic_words\"] = [\"government\", \"vic\", \"daniel\", \"andrew\", \"minister\"]\n",
    "\n",
    "mention = mention_time(\"GOvernment and @daniel !!andrew!!!\", keywords_list[\"vic_words\"], delimiter)\n",
    "mention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Obtain SA2 Area \n",
    "\n",
    "For example: use docs in `twitter/city/melbourne`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52619"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db_name = \"twitter/city/melbourne\"\n",
    "db = couch[db_name]\n",
    "all_docs = [i for i in db.view('_all_docs', include_docs=True)]\n",
    "len(all_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read grid file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from shapely.geometry import Polygon, MultiPolygon, Point\n",
    "\n",
    "with open(\"melb.json\") as file:\n",
    "    grid = json.loads(file.read())[\"features\"]\n",
    "\n",
    "polygons = []\n",
    "for loc in grid:\n",
    "    if loc[\"geometry\"][\"type\"] == \"Polygon\":\n",
    "        polygons.append(Polygon(loc[\"geometry\"]['coordinates'][0]))\n",
    "    else:\n",
    "        polygons.append(MultiPolygon([Polygon(each[0]) for each in loc[\"geometry\"]['coordinates']]))\n",
    "SA2_names = [loc[\"properties\"]['SA2_NAME16'] for loc in grid]\n",
    "SA2_codes_9_digits = [loc[\"properties\"]['SA2_MAIN16'] for loc in grid]\n",
    "SA2_codes_5_digits = [loc[\"properties\"]['SA2_5DIG16'] for loc in grid]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check SA2 Area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hampton Park - Lynbrook 212031305 21305\n",
      "Werribee - South 213051368 21368\n",
      "Werribee - West 213051468 21468\n",
      "Cranbourne 212031300 21300\n",
      "Berwick - South 212021294 21294\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for each in all_docs:\n",
    "    if count == 5:\n",
    "        break\n",
    "    doc = each.doc\n",
    "    if doc[\"coordinates\"] is not None:\n",
    "        count += 1\n",
    "        point = Point(doc[\"coordinates\"][\"coordinates\"])\n",
    "        for p, n, c1, c2 in zip(polygons, SA2_names, SA2_codes_9_digits, SA2_codes_5_digits):\n",
    "            if p.contains(point):\n",
    "                print(n, c1, c2)\n",
    "                break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 Complete Code for Making Modification\n",
    "\n",
    "Take database `a_twitter_test` as exmaple:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting update.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile update.py\n",
    "\n",
    "import couchdb\n",
    "import json\n",
    "import re\n",
    "import os\n",
    "from shapely.geometry import Polygon, MultiPolygon, Point\n",
    "from afinn import Afinn\n",
    "\n",
    "def mention_time(text, keyword_list, delimiter):\n",
    "    return sum([1 if token.lower() in keyword_list else 0 for token in re.split(delimiter, text)])\n",
    "\n",
    "# CouchDB URL\n",
    "url_connect = \"http://admin:A456852s@127.0.0.1:5984\"\n",
    "\n",
    "# Database list\n",
    "cities = [\"sydney\", \"brisbane\", \"melbourne\", \"perth\", \"adelaide\", \"canberra\"]\n",
    "db_names = [f\"twitter/city/{city}\" for city in cities]\n",
    "\n",
    "# Split delimiter\n",
    "delimiter = r\"[^a-zA-Z0-9\\-]\"\n",
    "\n",
    "# affin object\n",
    "afinn = Afinn()\n",
    "\n",
    "# Keywards\n",
    "keywords_list = dict()\n",
    "for filename in os.listdir():\n",
    "    if filename.endswith(\"txt\"):\n",
    "        with open(filename, \"r\") as file:\n",
    "            keywords_list[filename.split(\".\")[0]] = file.read().split()\n",
    "\n",
    "# Grid\n",
    "with open(\"melb.json\") as file:\n",
    "    grid = json.loads(file.read())[\"features\"]\n",
    "polygons = []\n",
    "for loc in grid:\n",
    "    if loc[\"geometry\"][\"type\"] == \"Polygon\":\n",
    "        polygons.append(Polygon(loc[\"geometry\"]['coordinates'][0]))\n",
    "    else:\n",
    "        polygons.append(MultiPolygon([Polygon(each[0]) for each in loc[\"geometry\"]['coordinates']]))\n",
    "area_list = dict()\n",
    "area_list[\"SA2_names\"] = [loc[\"properties\"]['SA2_NAME16'] for loc in grid]\n",
    "area_list[\"SA2_codes_9_digits\"] = [loc[\"properties\"]['SA2_MAIN16'] for loc in grid]\n",
    "area_list[\"SA2_codes_5_digits\"] = [loc[\"properties\"]['SA2_5DIG16'] for loc in grid]\n",
    "            \n",
    "if __name__ == \"__main__\":\n",
    "    # Connect CouchDB\n",
    "    couch = couchdb.Server(url_connect)\n",
    "    \n",
    "    # Get all database\n",
    "    for db_name in db_names:\n",
    "        db = couch[db_name]\n",
    "        \n",
    "        # Get all docs\n",
    "        all_docs = [i for i in db.view('_all_docs', include_docs=True)]\n",
    "        \n",
    "        # Get each doc\n",
    "        count = 1\n",
    "        length = len(all_docs)\n",
    "        for each_doc in all_docs:\n",
    "            this_doc = dict(each_doc.doc)\n",
    "            \n",
    "            # Load text info\n",
    "            if \"full_text\" in this_doc:\n",
    "                this_text = this_doc[\"full_text\"]\n",
    "            elif \"text\" in this_doc:\n",
    "                this_text = this_doc[\"text\"]\n",
    "            else:\n",
    "                count += 1 \n",
    "                continue\n",
    "            \n",
    "            # Add field: affin\n",
    "            this_doc[\"afinn\"] = afinn.score(this_text)\n",
    "            \n",
    "            # Add field: keywords\n",
    "            for key in keywords_list:\n",
    "                mention = mention_time(this_text, keywords_list[key], delimiter)\n",
    "                this_doc[key] = mention\n",
    "            \n",
    "            # Add field: SA2\n",
    "            if this_doc[\"coordinates\"] is not None:\n",
    "                point = Point(this_doc[\"coordinates\"][\"coordinates\"])\n",
    "                index = None\n",
    "                for i, polygon in enumerate(polygons):\n",
    "                    if polygon.contains(point):\n",
    "                        index = i\n",
    "                        break\n",
    "                for key in area_list:\n",
    "                    if index is not None:\n",
    "                        this_doc[key] = area_list[key][index]\n",
    "                    else:\n",
    "                        this_doc[key] = None\n",
    "            else:\n",
    "                for key in area_list:\n",
    "                    this_doc[key] = None\n",
    "                    \n",
    "            # Post each dock\n",
    "            db.save(this_doc)\n",
    "\n",
    "            # Print log\n",
    "            print(f\"{count}/{length} docs updated in database: {db_name}\", end='\\r')\n",
    "            count += 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Harvest Useful Tweets in 45.113.232.90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit\n",
    "import requests\n",
    "\n",
    "url = 'http://45.113.232.90/couchdbro/twitter/_design/twitter/_view/summary'\n",
    "params = {\n",
    "    'start_key': '[\"sydney\",2020,5,1]',\n",
    "    'end_key': '[\"sydney\",2020,5,1]',\n",
    "    'reduce': 'false',\n",
    "    'include_docs': 'true'\n",
    "}\n",
    "user = (\"readonly\", \"ween7ighai9gahR6\")\n",
    "\n",
    "req = requests.get(url, params=params, auth=user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63223"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%timeit\n",
    "docs = json.loads(req.text)['rows']\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = 1\n",
    "for i in range(len(docs)):\n",
    "    if docs[i]['doc'][\"coordinates\"] is not None:\n",
    "        count += 1\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'http://45.113.232.90/couchdbro/twitter/_design/twitter/_view/summary'\n",
    "params = {\n",
    "    'reduce': 'true',\n",
    "    'include_docs': 'false',\n",
    "    'group_level': 1\n",
    "}\n",
    "user = (\"readonly\", \"ween7ighai9gahR6\")\n",
    "\n",
    "req2 = requests.get(url, params=params, auth=user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rows': [{'key': ['adelaide'], 'value': 30951022},\n",
       "  {'key': ['brisbane'], 'value': 59529193},\n",
       "  {'key': ['canberra'], 'value': 18704632},\n",
       "  {'key': ['hobart'], 'value': 7349898},\n",
       "  {'key': ['melbourne'], 'value': 42033167},\n",
       "  {'key': ['perth'], 'value': 44301748},\n",
       "  {'key': ['sydney'], 'value': 96931480}]}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.loads(req2.text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
